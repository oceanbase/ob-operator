# FAQ

## 1. 如何查看资源已经 ready

以集群为例，您可以通过以下命令来查看资源状态：

```shell
kubectl get obclusters.oceanbase.oceanbase.com test -n oceanbase 
```

确认 status 状态，为 running 则表示资源可用。

```shell
# desired output 
NAME   STATUS    AGE
test   running   6m2s
```

## 2. 如何查看资源的运维状态

以集群为例，您可以通过以下命令来查看资源状态：

```shell
kubectl get obclusters.oceanbase.oceanbase.com test -n oceanbase -o yaml
```

operationContext 中记录了运维的状态，您可以通过观察这个字段了解运维的状态和进度。

```shell
status:
  image: oceanbase/oceanbase-cloud-native:4.2.0.0-101000032023091319
  obzones:
  - status: delete observer
    zone: obcluster-1-zone1
  - status: delete observer
    zone: obcluster-1-zone2
  - status: delete observer
    zone: obcluster-1-zone3
  operationContext:
    failureRule:
      failureStatus: running
      failureStrategy: retry over
      retryCount: 0
    idx: 2
    name: modify obzone replica
    targetStatus: running
    task: wait obzone topology match
    taskId: c04aeb28-01e7-4f85-b390-8d855b9f30e3
    taskStatus: running
    tasks:
    - modify obzone replica
    - wait obzone topology match
    - wait obzone running
  parameters: []
  status: modify obzone replica
```

## 3. ob-operator 如何排查问题

* ob-operator 的日志文件, 可以通过以下命令来查看，一般都是先分析 operator 的日志来找到具体哪里出现了错误。

```shell
kubectl logs oceanbase-controller-manager-86cfc8f7bf-js95z -n oceanbase-system -c manager  | less
```

* observer 的日志文件

```shell
# 登录到 observer 的容器
kubectl exec -it obcluster-1-zone1-8ab645f4d0f9 -n oceanbase -c observer -- bash

# 日志文件所在目录
cd /home/admin/oceanbase/log
```

## 4. ob-operator 如何修复“卡死”的资源

因为 ob-operator 采用基于状态机和任务流的机制来管理 CR (Custom Resource，自定义资源)及其运维操作，在配置出错、系统资源不足或者资源不匹配时，CR 有可能会陷入预期之外的状态，例如：不断重试一个必定失败的任务流、无法删除一个资源、误删资源但希望资源恢复运转等。当通过常规的 kubectl 操作无法将某一 CR 恢复正常时，可以借助 `OBResourceRescue` 资源对问题 CR 进行救治。`OBResourceRescue` 资源包含了四类操作：`重置`、`删除`、`重试`、`跳过`。

一个典型的 `OBResourceRescue` CR 配置如下所示：

```yaml
apiVersion: oceanbase.oceanbase.com/v1alpha1
kind: OBResourceRescue
metadata:
  generateName: rescue-reset- # generateName 需搭配 kubectl create -f 使用
spec:
  type: reset
  targetKind: OBCluster
  targetResName: test
  targetStatus: running # type 为 reset 时需要填写目标状态
```

其中关键配置如下表说明:

| 配置项 | 可选项 | 说明 |
| -- | -- | -- |
| type | `reset`, `delete`, `retry`, `skip` | 资源救治动作的类型 |
| targetKind | `OBCluster`, `OBZone`, `OBTenant` 等受 ob-operator 管理的 CRD Kind | 需要进行救治的资源 Kind |
| targetResName | / | 待救治的资源名称 |
| targetStatus | / | type 为 reset 需要填写该字段，表示资源重置后的状态 | 

### 重置

上述典型 CR 配置示例的配置信息就是重置类型的救治资源，将该资源通过 `kubectl create -f` 命令创建到 K8s 集群中后，会将 Kind 为 OBCluster，名为 test 的资源的 `status.status` 设置为 `running`（在配置文件中设置的 targetStatus），将该资源的 `status.operationContext` 置为空。

### 删除

删除类型的救治动作配置示例如下，它创建到集群中后，ob-operator 会将目标资源的 `finalizers` 字段清空，并将该资源的 `deletionTimestamp` 设置为当前时刻。

```yaml
# ...
spec:
  type: delete
  targetKind: OBCluster
  targetResName: test
```

### 重试

重试类型的救治动作配置示例如下，它创建到集群中后，ob-operator 会将目标资源的 `status.operationContext.retryCount` 置为 0，并且将 `status.operationContext.taskStatus` 置为 `pending`。处在该状态的资源将重试当前任务。

```yaml
# ...
spec:
  type: retry
  targetKind: OBCluster
  targetResName: test
```

### 跳过

跳过类型的救治动作配置示例如下，被创建到集群当中后，ob-operator 会把目标资源的 `status.operationContext.taskStatus` 直接置为 `successful`，任务管理器得到这个消息后会执行 `tasks` 中的下一个任务。 

```yaml
# ...
spec:
  type: skip
  targetKind: OBCluster
  targetResName: test
```